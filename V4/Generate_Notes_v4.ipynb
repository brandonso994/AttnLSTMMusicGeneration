{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "mount_file_id": "1GI1lj67mUgx88oIxus7GKOSvRsZsOuxk",
      "authorship_tag": "ABX9TyOfCqwxpkdpGFTIbDNeD45r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brandonso994/AttnLSTMMusicGeneration/blob/main/V4/Generate_Notes_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_self_attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVt6u2HbVp_A",
        "outputId": "49eca80e-76fa-433e-ca0b-f66df647fe91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_self_attention\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_self_attention) (1.22.4)\n",
            "Building wheels for collected packages: keras_self_attention\n",
            "  Building wheel for keras_self_attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras_self_attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18895 sha256=a1654c70a56d482084578473189081c051012e4a164b1f71358eeaeca88d874d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/f7/24/607b483144fb9c47b4ba2c5fba6b68e54aeee2d5bf6c05302e\n",
            "Successfully built keras_self_attention\n",
            "Installing collected packages: keras_self_attention\n",
            "Successfully installed keras_self_attention-0.51.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvYsr319-KMl"
      },
      "outputs": [],
      "source": [
        "from music21 import converter, instrument, note, chord, stream, volume\n",
        "from fractions import Fraction\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import numpy as np\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import LSTM, Dropout, Dense, Activation, Bidirectional, BatchNormalization, Input, Embedding, Concatenate, Flatten\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.metrics import CategoricalAccuracy\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras_self_attention import SeqSelfAttention"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZH8aXFs6ASGY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29715f44-9421-40e4-cf58-1ae24fba6a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(array):\n",
        "  new_array = [item for array in array for item in array]\n",
        "  return new_array\n",
        "\n",
        "# Create Sequence with window length = sequence_length for input into model\n",
        "def sequence(notes ,full_notes, note_set_len, sequence_length, midi_input):\n",
        "\n",
        "  note_values = sorted(set(note for note in full_notes))\n",
        "  note_encode = dict((note, num) for num, note in enumerate(note_values))\n",
        "\n",
        "  network_input_note = []\n",
        "  note_output = []\n",
        "\n",
        "  for i in range (len(notes) - sequence_length):\n",
        "    sequence_in_note = notes[i:i + sequence_length]\n",
        "    sequence_out = notes[i + sequence_length]\n",
        "    network_input_note.append([note_encode[note] for note in sequence_in_note])\n",
        "    note_output.append(note_encode[sequence_out])\n",
        "    if midi_input:\n",
        "      break\n",
        "\n",
        "  n_patterns = len(network_input_note)\n",
        "\n",
        "  network_input_note_norm = np.reshape(network_input_note, (n_patterns, sequence_length, 1))\n",
        "  network_input_note_norm = network_input_note_norm / float(note_set_len)\n",
        "\n",
        "  note_output = np_utils.to_categorical(note_output)\n",
        "\n",
        "  return network_input_note, network_input_note_norm\n",
        "\n",
        "def create_model(network_input_note, note_set_len, version_num):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Note input\n",
        "    model.add(Bidirectional(LSTM(512,return_sequences=True),input_shape=(network_input_note.shape[1], network_input_note.shape[2])))\n",
        "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(LSTM(512,return_sequences=False))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(note_set_len, activation='softmax', name='note'))\n",
        "    model.load_weights('/content/drive/My Drive/MRP/Model/model_weights_' + version_num + '_checkpoints.h5')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Predicts the next note given the sequence\n",
        "def note_prediction(model, note_input, notes, seq_len, num_notes=500, midi_input=False, temp=0.8):\n",
        "  note_set_len = len(set(notes))\n",
        "\n",
        "  note_values = sorted(set(note for note in notes))\n",
        "\n",
        "  note_decode = dict((num, note) for num, note in enumerate(note_values))\n",
        "  note_encode = dict((note, num) for num, note in enumerate(note_values))\n",
        "\n",
        "  # Whether input was given, or start randomly from sequence\n",
        "  if midi_input:\n",
        "    start = 0\n",
        "  else:\n",
        "    start = np.random.randint(0, len(note_input) - 1)\n",
        "\n",
        "  generated_notes = []\n",
        "  note_pattern = note_input[start]\n",
        "\n",
        "  # Loop, predicting each note and appending the prediction to the sequence, removing the oldest note to preserve sequence length\n",
        "  for item in range(num_notes):\n",
        "    prediction_input = np.reshape(note_pattern, (1, len(note_pattern), 1))\n",
        "    prediction_input = prediction_input / float(note_set_len)\n",
        "\n",
        "    predictions = model.predict(prediction_input, verbose=0)\n",
        "\n",
        "    predicted_note = predictions\n",
        "\n",
        "    # Apply temperature\n",
        "    predicted_note = np.log(predicted_note) / temp\n",
        "\n",
        "    note_probs = np.exp(predicted_note) / np.sum(np.exp(predicted_note))\n",
        "\n",
        "    # Sample the next pitch and duration using the temperature-adjusted probabilities\n",
        "    next_note = np.random.choice(len(note_probs[0]), p=note_probs[0])\n",
        "\n",
        "    decoded_note = note_decode[next_note]\n",
        "    generated_notes.append(decoded_note)\n",
        "    note_pattern.append(next_note)\n",
        "    note_pattern = note_pattern[1:len(note_pattern)]\n",
        "\n",
        "    # Decrease temperature slowly if greater than 1\n",
        "    if temp > 1:\n",
        "      temp -= 0.2\n",
        "\n",
        "\n",
        "  return generated_notes\n",
        "\n",
        "# Generate midi from predicted notes\n",
        "def generate_midi(note_sequence, file_num, version_num):\n",
        "  output_notes = []\n",
        "  offset = 0\n",
        "  isRest = False\n",
        "  for output_note in note_sequence:\n",
        "      output_note = output_note.split()\n",
        "      temp = output_note[0]\n",
        "      duration = float(output_note[1].split(':')[0])\n",
        "      new_offset = float(output_note[1].split(':')[1])\n",
        "      output_pitch = temp\n",
        "      # If chord\n",
        "      if ('.' in output_pitch) or output_pitch.isdigit():\n",
        "          notes_in_chord = output_pitch.split('.')\n",
        "          notes = []\n",
        "          for current_note in notes_in_chord:\n",
        "              new_note = note.Note(int(current_note))\n",
        "              notes.append(new_note)\n",
        "          new_chord = chord.Chord(notes)\n",
        "          new_chord.duration.quarterLength = float(duration)\n",
        "          new_chord.offset = offset\n",
        "          output_notes.append(new_chord)\n",
        "      else:\n",
        "          new_note = note.Note(output_pitch)\n",
        "          new_note.offset = offset\n",
        "          new_note.duration.quarterLength = float(duration)\n",
        "          output_notes.append(new_note)\n",
        "      offset += new_offset\n",
        "\n",
        "  midi_stream = stream.Stream(output_notes)\n",
        "  piano = instrument.Piano()\n",
        "  midi_stream.insert(0, piano)\n",
        "  midi_stream.write('midi', fp='/content/drive/My Drive/MRP/test_file_' + str(version_num) + '_' + str(file_num) + '.midi')\n",
        "\n",
        "  return\n",
        "\n",
        "def generate(version_num, file_num, midi_input=False, load=False, num_notes=500):\n",
        "  seq_len = 60\n",
        "\n",
        "  if midi_input:\n",
        "    with open('simple_notes_offsets_midi.pkl', 'rb') as f:\n",
        "      midi_note = pickle.load(f)\n",
        "\n",
        "    midi_note = flatten(midi_note)\n",
        "\n",
        "  with open('simple_notes_offsets.pkl', 'rb') as f:\n",
        "    notes = pickle.load(f)\n",
        "\n",
        "  notes = flatten(notes)\n",
        "  note_set_len = len(set(notes))\n",
        "\n",
        "  if midi_input:\n",
        "    print(midi_input)\n",
        "    note_input, note_input_norm = sequence(midi_note, notes, note_set_len, seq_len, midi_input)\n",
        "  else:\n",
        "    note_input, note_input_norm = sequence(notes, notes, note_set_len, seq_len, midi_input)\n",
        "\n",
        "  model = create_model(note_input_norm, note_set_len, version_num)\n",
        "  generated_notes = note_prediction(model, note_input, notes, seq_len, num_notes, midi_input=midi_input)\n",
        "\n",
        "  generate_midi(generated_notes, file_num, version_num)\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wnmVEF2X-Op0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(5,11):\n",
        "  generate('v4_3', x)"
      ],
      "metadata": {
        "id": "svczlKf_ZgRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range (1,4):\n",
        "  generate(\"v4_4_2\", \"Hayden\" + \"_\" + str(x), midi_input=True, num_notes = 300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcC4H1zj1R0U",
        "outputId": "bde972ac-21ed-48f5-e402-5f4f9599aa67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    }
  ]
}